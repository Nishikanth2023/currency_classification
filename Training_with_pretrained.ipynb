{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Pr0i2YaUnWx"
      },
      "outputs": [],
      "source": [
        "# import the libraries as shown below\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "import numpy as np\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/dataset2/processed_dF2'\n",
        "valid_path = '/content/drive/MyDrive/Colab Notebooks/dataset2/val2'"
      ],
      "metadata": {
        "id": "UfoxGwkAU4Xn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = glob('/content/drive/MyDrive/Colab Notebooks/dataset2/processed_dF2/*')"
      ],
      "metadata": {
        "id": "HXaeinWJU9Jp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pel2ZrWEU9L7",
        "outputId": "c4d09b55-e422-43a3-8168-6c067bd79b9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/dataset2/processed_dF2/200',\n",
              " '/content/drive/MyDrive/Colab Notebooks/dataset2/processed_dF2/100',\n",
              " '/content/drive/MyDrive/Colab Notebooks/dataset2/processed_dF2/500',\n",
              " '/content/drive/MyDrive/Colab Notebooks/dataset2/processed_dF2/50',\n",
              " '/content/drive/MyDrive/Colab Notebooks/dataset2/processed_dF2/20',\n",
              " '/content/drive/MyDrive/Colab Notebooks/dataset2/processed_dF2/1',\n",
              " '/content/drive/MyDrive/Colab Notebooks/dataset2/processed_dF2/10']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   featurewise_center=True,\n",
        "                                   rotation_range=0.4,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255,)"
      ],
      "metadata": {
        "id": "T9Sv332-V3aW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/dataset2/processed_dF2',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZXUAsCZV3fZ",
        "outputId": "d4bfc44b-b7e3-42d8-a6fa-99c3e23a0a20"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1447 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/dataset2/val2',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0PJumoCV3iO",
        "outputId": "7511bfa1-6d1f-4c15-895d-d7b79cfef1cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 96 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpRQwaRsb9PB",
        "outputId": "041fed3c-2ec6-450e-cd84-68b5d42300f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "SdViKaJHb9Rg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(base_model.output)\n",
        "\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "# Add a dropout rate of 0.5\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Add a final sigmoid layer with 1 node for classification output\n",
        "x = layers.Dense(7, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(base_model.input, x)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V4R_-axb9UT",
        "outputId": "8fb1f774-75b7-4c9c-dd7d-acdd8a0e07ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit(training_set, validation_data = test_set, steps_per_epoch = len(training_set), epochs = 10, validation_steps=len(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylT6zXkcd_7h",
        "outputId": "d30d3d20-e82e-42b4-f13f-4ec51baf0283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "46/46 [==============================] - 1116s 24s/step - loss: 2.9062 - accuracy: 0.2730 - val_loss: 2.0364 - val_accuracy: 0.1979\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 1083s 23s/step - loss: 1.5941 - accuracy: 0.3960 - val_loss: 1.4895 - val_accuracy: 0.4792\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 1109s 24s/step - loss: 1.3161 - accuracy: 0.5052 - val_loss: 1.4055 - val_accuracy: 0.4479\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 1091s 24s/step - loss: 1.1642 - accuracy: 0.5681 - val_loss: 1.1054 - val_accuracy: 0.5938\n",
            "Epoch 5/10\n",
            "13/46 [=======>......................] - ETA: 12:18 - loss: 1.0624 - accuracy: 0.6058"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier=Sequential()\n",
        "\n",
        "# Classifier.add(Conv2D(32,(3,3), input_shape=(224,224,3), activation='relu'))\n",
        "# Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Classifier.add(Conv2D(32,(3,3),activation='relu'))\n",
        "# Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Classifier.add(Flatten())\n",
        "\n",
        "# Classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "# Classifier.add(Dense(units = 7, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "9fLN2cSAU9Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # tell the model what cost and optimization method to use\n",
        "# Classifier.compile(\n",
        "#   loss='categorical_crossentropy',\n",
        "#   optimizer='adam',\n",
        "#   metrics=['accuracy']\n",
        "# )"
      ],
      "metadata": {
        "id": "EUA8P5jPU9Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # fit the model\n",
        "# from PIL import _imaging\n",
        "# from PIL import Image\n",
        "# import PIL\n",
        "# # Run the cell. It will take some time to execute\n",
        "# r = Classifier.fit_generator(\n",
        "#   training_set,\n",
        "#   validation_data=test_set,\n",
        "#   epochs=50,#Take Epochs = 50\n",
        "#   steps_per_epoch=len(training_set),\n",
        "#   validation_steps=len(test_set)\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbNO6i-OU9Tg",
        "outputId": "8f990ba3-2e6b-4af0-926c-c97a9b612dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-658e36c788aa>:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  r = Classifier.fit_generator(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py:1862: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "46/46 [==============================] - 636s 14s/step - loss: 2.0062 - accuracy: 0.2633 - val_loss: 1.3587 - val_accuracy: 0.5417\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 146s 3s/step - loss: 1.2804 - accuracy: 0.5114 - val_loss: 0.9628 - val_accuracy: 0.6458\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 143s 3s/step - loss: 0.9711 - accuracy: 0.6351 - val_loss: 1.2460 - val_accuracy: 0.4896\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 134s 3s/step - loss: 0.7782 - accuracy: 0.7173 - val_loss: 0.7691 - val_accuracy: 0.6771\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 148s 3s/step - loss: 0.7416 - accuracy: 0.7180 - val_loss: 0.7365 - val_accuracy: 0.6667\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 148s 3s/step - loss: 0.6068 - accuracy: 0.7816 - val_loss: 0.7655 - val_accuracy: 0.6875\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 145s 3s/step - loss: 0.5204 - accuracy: 0.8134 - val_loss: 1.4617 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 132s 3s/step - loss: 0.5121 - accuracy: 0.8120 - val_loss: 0.8910 - val_accuracy: 0.6562\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 136s 3s/step - loss: 0.3867 - accuracy: 0.8735 - val_loss: 0.8719 - val_accuracy: 0.6667\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 131s 3s/step - loss: 0.3983 - accuracy: 0.8625 - val_loss: 0.7993 - val_accuracy: 0.7188\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 150s 3s/step - loss: 0.3388 - accuracy: 0.8874 - val_loss: 1.0473 - val_accuracy: 0.6979\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 140s 3s/step - loss: 0.3041 - accuracy: 0.8922 - val_loss: 0.8490 - val_accuracy: 0.7083\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 139s 3s/step - loss: 0.2981 - accuracy: 0.9046 - val_loss: 0.8704 - val_accuracy: 0.6771\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 137s 3s/step - loss: 0.4726 - accuracy: 0.8500 - val_loss: 1.2013 - val_accuracy: 0.5312\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 145s 3s/step - loss: 0.2496 - accuracy: 0.9226 - val_loss: 1.1874 - val_accuracy: 0.6354\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 133s 3s/step - loss: 0.1730 - accuracy: 0.9399 - val_loss: 1.2654 - val_accuracy: 0.6875\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 143s 3s/step - loss: 0.1789 - accuracy: 0.9392 - val_loss: 1.1862 - val_accuracy: 0.6875\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 133s 3s/step - loss: 0.1644 - accuracy: 0.9475 - val_loss: 1.1338 - val_accuracy: 0.7188\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 143s 3s/step - loss: 0.1381 - accuracy: 0.9496 - val_loss: 1.0820 - val_accuracy: 0.6562\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 132s 3s/step - loss: 0.1118 - accuracy: 0.9641 - val_loss: 0.9699 - val_accuracy: 0.7188\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 141s 3s/step - loss: 0.1087 - accuracy: 0.9648 - val_loss: 1.3255 - val_accuracy: 0.6354\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 131s 3s/step - loss: 0.0992 - accuracy: 0.9668 - val_loss: 1.1594 - val_accuracy: 0.6875\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 134s 3s/step - loss: 0.1043 - accuracy: 0.9613 - val_loss: 0.9722 - val_accuracy: 0.6979\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 132s 3s/step - loss: 0.1620 - accuracy: 0.9447 - val_loss: 1.3670 - val_accuracy: 0.7188\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 137s 3s/step - loss: 0.1472 - accuracy: 0.9482 - val_loss: 1.3841 - val_accuracy: 0.6042\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 138s 3s/step - loss: 0.0678 - accuracy: 0.9786 - val_loss: 1.6547 - val_accuracy: 0.6979\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 132s 3s/step - loss: 0.0715 - accuracy: 0.9779 - val_loss: 1.3455 - val_accuracy: 0.6771\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 132s 3s/step - loss: 0.0386 - accuracy: 0.9917 - val_loss: 1.5002 - val_accuracy: 0.6979\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 133s 3s/step - loss: 0.0539 - accuracy: 0.9820 - val_loss: 1.6042 - val_accuracy: 0.7188\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 147s 3s/step - loss: 0.0825 - accuracy: 0.9730 - val_loss: 2.0427 - val_accuracy: 0.6771\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 133s 3s/step - loss: 0.0640 - accuracy: 0.9786 - val_loss: 1.6660 - val_accuracy: 0.6667\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 131s 3s/step - loss: 0.0662 - accuracy: 0.9779 - val_loss: 1.0713 - val_accuracy: 0.6979\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 133s 3s/step - loss: 0.0695 - accuracy: 0.9793 - val_loss: 1.5497 - val_accuracy: 0.7083\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 133s 3s/step - loss: 0.0713 - accuracy: 0.9779 - val_loss: 1.7592 - val_accuracy: 0.6771\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 131s 3s/step - loss: 0.0724 - accuracy: 0.9751 - val_loss: 1.3132 - val_accuracy: 0.6875\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 133s 3s/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 1.2773 - val_accuracy: 0.6875\n",
            "Epoch 37/50\n",
            "19/46 [===========>..................] - ETA: 1:20 - loss: 0.0427 - accuracy: 0.9918"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.history"
      ],
      "metadata": {
        "id": "L0fJylQiWNah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "metadata": {
        "id": "JMe5zPJEWQA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save it as a h5 file\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "Classifier.save('/content/drive/MyDrive/Colab Notebooks/models/extra_data_model.h5')"
      ],
      "metadata": {
        "id": "tewTxic6WQDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z1McH3vIWQGN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}